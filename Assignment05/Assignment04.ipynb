{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 594 / CS 690 - Assignment 04 \n",
    "### September 24, 2018\n",
    "---\n",
    "\n",
    "For this assignment, you must work in groups of one or two students. Each person is responsible to write their own code, but the group will (together) discuss their solution.  In this notebook, we provide you with basic functions for completing the assignment.  *Complete the assignment in this notebook.  You will need to modify existing code and write new code to find a solution*.  Each member of the group must upload their own work (i.e., a notebook file) to GitHub.\n",
    "\n",
    "*Note: Running a cell will not rerun previous cells.  If you edit code in previous cells, you must rerun those cells.  If you are having trouble with undefined errors and code changes not applying, we recommend using* `Run All` *to avoid any errors results from not rerunning previous cells.  You can find this in the menu above:* `Cell -> Run All`\n",
    "\n",
    "During lecture 3, we learned about the **MapReduce** programming model.  In this assignment, we will use **MapReduce** programming model to perform the text parsing problems that we solved in assignment 3 *with the power of the MapReduce programming model*.  Python provides a `map` and `reduce` for iterables that do not take advantage of parallel processing (i.e., they are sequential), but they work in a similar way to the parallel implementations you find in *Apache Spark*.  We define three methods (i.e., `mapSequential`, `reduceSequential`, and `reduceByKeySequential`) that extend Python's `map` and `reduce` functions to act like those in *Apache Spark*.  We will use *sequential* **MapReduce** to develop methods that can be used with the *parallel* **MapReduce** from *Apache Spark*.\n",
    "\n",
    "In the following table, we have listed examples of inputs and outputs to different **MapReduce** methods.  See if you can determine how the output was computed with the input:\n",
    "\n",
    "| Input                          | Function   | MapReduce Call | Output               |\n",
    "|--------------------------------|------------|----------------|----------------------|\n",
    "| [1,2,3]                        | f(x)=x+1   | Map            | [2,3,4]              |\n",
    "| [1,2,3]                        | f(x,y)=x+y | Reduce         | 6                    |\n",
    "| [('a', 1), ('b', 2), ('a', 3)] | f(x,y)=x+y | ReduceByKey    | [('a', 4), ('b', 2)] |\n",
    "\n",
    "Now let's check that these functions work with out sequential implementation of `map`, `reduce`, and `reduceByKey`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "from itertools import groupby\n",
    "# We wrap the original python map and reduce functions to be more powerful and resilient\n",
    "def mapSequential(data, func):\n",
    "    return list(map(func, data))\n",
    "\n",
    "def reduceSequential(data, func):\n",
    "    return functools.reduce(func, data)\n",
    "\n",
    "def reduceByKeySequential(data, func):\n",
    "    reduced_data = []\n",
    "    for key, vals in itertools.groupby(sorted(data, key=lambda x: x[0]), key=lambda x: x[0]):\n",
    "        reduced_data.append((key, reduceSequential([x[1] for x in vals], func)))\n",
    "    return reduced_data\n",
    "\n",
    "def reduceByKeySeq (data, func):\n",
    "    reduced_data = []\n",
    "    reduced_data = [(key, [i[1] for i in values]) for key, values in groupby(data, lambda i: i[0])]\n",
    "    return reduced_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: [2, 3, 4]\n",
      "Output 2: 6\n",
      "Output 3: [('a', 4), ('b', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Define our three inputs\n",
    "input_1 = [1,2,3]\n",
    "input_2 = [1,2,3]\n",
    "input_3 = [('a', 1), ('b', 2), ('a', 3)]\n",
    "\n",
    "# Define the two functions used\n",
    "def plusOne(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Apply our functions to our inputs\n",
    "output_1 = mapSequential(input_1, plusOne)\n",
    "output_2 = reduceSequential(input_2, add)\n",
    "output_3 = reduceByKeySequential(input_3, add)\n",
    "\n",
    "# Print out outputs\n",
    "print('Output 1:', output_1)\n",
    "print('Output 2:', output_2)\n",
    "print('Output 3:', output_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing:\n",
    "Below is code to open a text file and return a list of words containing only upper-case unicode characters.  We use this to read the text file (i.e., \"The Count of Monte Cristo\") and prepare the text for the following three problems.  The output, which you should use for solving the assignment problems, is named `words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regular expressions library\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a method for reading and processing text files\n",
    "def loadText(f_name):\n",
    "    # Read the text file\n",
    "    with open(f_name, 'r') as f:\n",
    "        text_lines = f.readlines()\n",
    "\n",
    "    # Concatenate the list of strings into a single string\n",
    "    text_all = ''.join(text_lines)\n",
    "\n",
    "    # Remove all non-alphabet characters with a regular expression\n",
    "    text_alpha = re.sub(r'[^a-zA-Z]', ' ', text_all)\n",
    "\n",
    "    # Convert characters to upper-case\n",
    "    text_upper = text_alpha.upper()\n",
    "    \n",
    "    # Convert the string of text into a list of words and remove empty words\n",
    "    words = [w for w in text_upper.split(' ') if w is not '']\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "# Load list of words\n",
    "words = loadText('book_CountOfMonteCristo.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:\n",
    "Analyze the text for word length frequency. We might expect short words to be more common than long words. But, are words of length 2 more common than words or length 3? Are words of length 3 more common that words of length 4? **Use the pre-processed text, `words`, from the previous cell to count the frequency of each word length in the text using the sequential MapReduce methods we defined above**.  \n",
    "\n",
    "*Complete the definition of functions in the following cell.  These functions are used in the next cell with the `map` and `reduce` calls that we have defined for you above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the length of a given word\n",
    "def wordLength(word): \n",
    "    return len(word)\n",
    "\n",
    "# Given a key and value, return a (key, value) pair\n",
    "def makeKeyValue(key, value=1):     \n",
    "    return (key,value)\n",
    "    \n",
    "# Count (reduce) the values for a given key (word length)\n",
    "def addValues(val1, val2):\n",
    "    return val1 + val2\n",
    "\n",
    "def returnValues(value):\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Length : Count\n",
      "3           : 109798\n",
      "2           :  84021\n",
      "4           :  81777\n",
      "5           :  49101\n",
      "6           :  39015\n",
      "7           :  30701\n"
     ]
    }
   ],
   "source": [
    "word_lengths = mapSequential(words, wordLength)\n",
    "word_keyvalues = mapSequential(word_lengths, makeKeyValue)\n",
    "word_length_counts = reduceByKeySequential(word_keyvalues, addValues)\n",
    "\n",
    "wl_counts_sorted = sorted(word_length_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('Word Length : Count')\n",
    "for word_len, count in wl_counts_sorted[:6]:\n",
    "    print('{:<11d} : {:>6d}'.format(word_len, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Word Length : Count\n",
    "3           : 109798\n",
    "2           :  84021\n",
    "4           :  81777\n",
    "5           :  49101\n",
    "6           :  39015\n",
    "7           :  30701\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "For this problem, it may be beneficial to use another **MapReduce** function from *Apache Spark*: `flatMap`.  We define `flatMapSequential` below.  `flatMap` has the ability to expand the number of elements in a mapped iterable by flattening a list of lists into a single list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatMapSequential(data, func):\n",
    "    mapped_data = mapSequential(data, func)\n",
    "    flattened_data = [item for lst in mapped_data for item in lst]\n",
    "    return flattened_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you become familiar with `flatMap`, we have an example below which should make the difference between `map` and `flatMap` apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "flatmap: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Define a list of lists of integers for testing\n",
    "test = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "# Define a function that returns the input\n",
    "def dummyFunc(x):\n",
    "    return x\n",
    "\n",
    "# Let's apply a map with our dummy function\n",
    "test_map = mapSequential(test, dummyFunc)\n",
    "print('map:', test_map)\n",
    "\n",
    "# Let's apply a flatMap with our dummy function\n",
    "test_flatmap= flatMapSequential(test, dummyFunc)\n",
    "print('flatmap:', test_flatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the different between `map` and `flatMap`?  If not, modify the code and try it with a different input or different function.  In general, the function with which you call `flatMap` should return an iterable (e.g., list or tuple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting back to the problem...  Analyze the text for letter frequency. If you’ve taken a crypto course and/or have seen substitution ciphers then you are probably aware that ’e’ is the most common letter used in the English language.  **Use the pre-processed text `words` to count the frequency of each letter in the text using the sequential MapReduce methods we defined above**. \n",
    "\n",
    "*Complete the `splitWord` function in the following cell, then fill in the code in the cell after. Much of this code will be similar to the final cell of Problem 1, including `map` and `reduce` calls using functions defined in Problem 1.  Did you write those functions general enough to be reused?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a word, return an iterable of characters\n",
    "def splitWord(word):\n",
    "    data = word.split(' ',0) \n",
    "    for a in data:\n",
    "        return list(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character   : Count\n",
      "E           : 258693\n",
      "T           : 180211\n",
      "A           : 165306\n",
      "O           : 156817\n",
      "I           : 142095\n",
      "N           : 137343\n"
     ]
    }
   ],
   "source": [
    "l = [splitWord(word) for word in words]\n",
    "\n",
    "chars = flatMapSequential(l, dummyFunc)\n",
    "char_keyvalues = mapSequential(chars, makeKeyValue)\n",
    "char_counts = reduceByKeySequential(char_keyvalues, addValues)\n",
    "\n",
    "char_counts_sorted = sorted(char_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('Character   : Count')\n",
    "for char, count in char_counts_sorted[:6]:\n",
    "    print('{:<11} : {:>6d}'.format(char, count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Character : Count\n",
    "E         : 258693\n",
    "T         : 180211\n",
    "A         : 165306\n",
    "O         : 156817\n",
    "I         : 142095\n",
    "N         : 137343\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "For this problem, it may be beneficial to use the `numpy` package.  Specifically, the element-wise addition of numpy array may come in handy.  Below is an example of what happens when you add two numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  a: [1 1 0]\n",
      "  b: [0 1 0]\n",
      "a+b: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see a useful property of numpy arrays\n",
    "# HINT: ref [1]\n",
    "import numpy as np\n",
    "\n",
    "# Define numpy arrays\n",
    "a = np.array([1,1,0])\n",
    "b = np.array([0,1,0])\n",
    "\n",
    "# Print each array and the sum of each array\n",
    "print('  a:', a)\n",
    "print('  b:', b)\n",
    "print('a+b:', a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- [1: numpy quickstart](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really wanted to crack a substitution cipher (or win on ”Wheel of Fortune”) then we should be aware that, although ’e’ is the most common letter used in English, it may not be the most common first letter in a word. **Count the positional frequencies of each letter using the sequential MapReduce methods we defined above. Specifically, count the number of times each letter appears as the first letter in a word, as the last letter in a word, and as an interior letter in a word (i.e. a letter that is neither first nor last)**.  \n",
    "\n",
    "*Complete the `lettersPosition` function below, then fill in the code in the cell after.  Your functions are used with `map` and `reduce` calls that we have defined.  Note that we use a function that has also been used in Problems 1 and 2. Using numpy arrays in the following function definition could make this assignment easier.  However, you are not required to use numpy.  Feel free to change code by adding more maps or reduces in order to get a correct answer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lettersPosition(word):\n",
    "    if len(word) == 1:\n",
    "        return [(word, 0)]\n",
    "    else:\n",
    "        first, last = word[0], word[-1]\n",
    "        pos_list = [(first, 0), (last, 2)]\n",
    "\n",
    "        interior = word[1:-1]\n",
    "        for char in interior:\n",
    "            pos_list.append((char, 1))\n",
    "\n",
    "    return pos_list\n",
    "\n",
    "\n",
    "def ReduceElements(w):\n",
    "    ls = []\n",
    "    tup = ()\n",
    "    for k in w:\n",
    "        y = list(k[0]+(k[1],))\n",
    "        y.pop(1)\n",
    "        x = tuple(y)\n",
    "        ls.append(x)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : First | Interior |  Last\n",
      "A         : 51644 |   111686 |  1976\n",
      "B         : 18866 |     8516 |   541\n",
      "C         : 19577 |    32130 |   725\n",
      "D         : 17289 |    18613 | 58075\n",
      "E         : 10178 |   153205 | 95310\n",
      "F         : 17724 |    10618 | 16988\n"
     ]
    }
   ],
   "source": [
    "l = [lettersPosition (w) for w in words]\n",
    "\n",
    "char_pos = flatMapSequential(l, dummyFunc)\n",
    "char_positions = mapSequential(char_pos, makeKeyValue)\n",
    "char_position_counts = reduceByKeySequential(char_positions, addValues)\n",
    "\n",
    "cp = sorted (char_position_counts, key=lambda x: x[0]) \n",
    "\n",
    "cp_sorted = reduceByKeySeq(ReduceElements(cp),returnValues)\n",
    "\n",
    "print('Character : First | Interior |  Last')\n",
    "\n",
    "for char, char_position in cp_sorted[:6]:\n",
    "    first, interior, last = char_position\n",
    "    print('{:<9} : {:5d} | {:>8d} | {:>5d}'.format(char, first, interior, last))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Character : First | Interior |  Last\n",
    "A         : 51644 |   111686 |  1976\n",
    "B         : 18866 |     8516 |   541\n",
    "C         : 19577 |    32130 |   725\n",
    "D         : 17289 |    18613 | 58075\n",
    "E         : 10178 |   153205 | 95310\n",
    "F         : 17724 |    10618 | 16988\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4:\n",
    "Repeat Problem 2 with a new text, one you expect to have different letter distribution than The Count of Monty Cristo. You could use something written centuries earlier (e.g., Shakespeare or an early English translation of the Bible), in a distinctive style or genre (e.g., poetry or a contract), or even in a different language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character   :  Count\n",
      "E           :  11881\n",
      "T           :   7952\n",
      "O           :   6868\n",
      "A           :   6580\n",
      "N           :   5584\n",
      "S           :   5533\n"
     ]
    }
   ],
   "source": [
    "words = loadText('Macbeth.txt')\n",
    "l = [splitWord(word) for word in words]\n",
    "\n",
    "chars = flatMapSequential(l, dummyFunc)\n",
    "char_keyvalues = mapSequential(chars, makeKeyValue)\n",
    "char_counts = reduceByKeySequential(char_keyvalues, addValues)\n",
    "\n",
    "char_counts_sorted = sorted(char_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('Character   :  Count')\n",
    "for char, count in char_counts_sorted[:6]:\n",
    "    print('{:<11} : {:>6d}'.format(char, count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Consider:\n",
    "In this assignment you wrote functions that can be used with the **MapReduce** programming model.  The `map` and `reduce` functions were sequential, but they work in the same way as the parallel versions.  This means that the functions you wrote in this assignment can be used in the next assignment where we use **MapReduce** in parallel with *Apache Spark*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Questions:\n",
    "**Answer the following questions, in a couple sentences each, in the cells provided below**\n",
    "* List the key tasks you accomplished during this assignment?\n",
    "* Describe the challenges you faced in addressing these tasks and how you overcame these challenges?\n",
    "* Did you work with other students on this assignment? If yes, how did you help them? How did they help you? Be as specific as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Tasks:**\n",
    "* Use the sequential map and reduce functions to count the frequency of each word length and each letter, as well \n",
    "  as the positional frequency of each letter.\n",
    "* Compare the letter distributions between two different books, one written around two and a half centuries \n",
    "  earlier than the other.\n",
    "  \n",
    "**Challenges:**\n",
    "* In problem 3, printing the output in a certain way posed a challenge for me. But later I overcame it by using \n",
    "  some additional functions.\n",
    "  \n",
    "**No, I didn't get any chance to work with others during this assignment.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
